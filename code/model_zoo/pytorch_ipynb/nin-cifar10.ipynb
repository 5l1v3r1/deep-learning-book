{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "*Accompanying code examples of the book \"Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python\" by [Sebastian Raschka](https://sebastianraschka.com). All code examples are released under the [MIT license](https://github.com/rasbt/deep-learning-book/blob/master/LICENSE). If you find this content useful, please consider supporting the work by buying a [copy of the book](https://leanpub.com/ann-and-deeplearning).*\n",
    "  \n",
    "Other code examples and content are available on [GitHub](https://github.com/rasbt/deep-learning-book). The PDF and ebook versions of the book are available through [Leanpub](https://leanpub.com/ann-and-deeplearning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1524974472601,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "GOzuY8Yvj5wb",
    "outputId": "c19362ce-f87a-4cc2-84cc-8d7b4b9e6007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.6.8\n",
      "IPython 7.2.0\n",
      "\n",
      "torch 1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rH4XmErYj5wm"
   },
   "source": [
    "# Model Zoo -- Network in Network CIFAR-10 Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "DEVICE = \"cuda:0\"\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell that implements the ResNet-34 architecture is a derivative of the code provided at https://pytorch.org/docs/0.4.0/_modules/torchvision/models/resnet.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Image batch dimensions: torch.Size([256, 3, 32, 32])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Image batch dimensions: torch.Size([256, 3, 32, 32])\n",
      "Image label dimensions: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### CIFAR-10 Dataset\n",
    "##########################\n",
    "\n",
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "train_dataset = datasets.CIFAR10(root='data', \n",
    "                                 train=True, \n",
    "                                 transform=transforms.ToTensor(),\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='data', \n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_workers=8,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=8,\n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "class NiN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NiN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.classifier = nn.Sequential(\n",
    "                nn.Conv2d(3, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 160, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(160,  96, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                nn.Conv2d(96, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192,  10, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=8, stride=1, padding=0),\n",
    "\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        logits = x.view(x.size(0), self.num_classes)\n",
    "        probas = torch.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = NiN(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/050 | Batch 0000/0196 | Cost: 2.3002\n",
      "Epoch: 001/050 | Batch 0150/0196 | Cost: 2.0776\n",
      "Epoch: 001/050 | Train: 23.810%\n",
      "Time elapsed: 0.32 min\n",
      "Epoch: 002/050 | Batch 0000/0196 | Cost: 1.9796\n",
      "Epoch: 002/050 | Batch 0150/0196 | Cost: 1.8938\n",
      "Epoch: 002/050 | Train: 27.458%\n",
      "Time elapsed: 0.64 min\n",
      "Epoch: 003/050 | Batch 0000/0196 | Cost: 1.9004\n",
      "Epoch: 003/050 | Batch 0150/0196 | Cost: 1.7400\n",
      "Epoch: 003/050 | Train: 30.426%\n",
      "Time elapsed: 0.97 min\n",
      "Epoch: 004/050 | Batch 0000/0196 | Cost: 1.8689\n",
      "Epoch: 004/050 | Batch 0150/0196 | Cost: 1.6299\n",
      "Epoch: 004/050 | Train: 35.662%\n",
      "Time elapsed: 1.32 min\n",
      "Epoch: 005/050 | Batch 0000/0196 | Cost: 1.6710\n",
      "Epoch: 005/050 | Batch 0150/0196 | Cost: 1.7306\n",
      "Epoch: 005/050 | Train: 36.898%\n",
      "Time elapsed: 1.66 min\n",
      "Epoch: 006/050 | Batch 0000/0196 | Cost: 1.5936\n",
      "Epoch: 006/050 | Batch 0150/0196 | Cost: 1.7595\n",
      "Epoch: 006/050 | Train: 37.268%\n",
      "Time elapsed: 2.00 min\n",
      "Epoch: 007/050 | Batch 0000/0196 | Cost: 1.6505\n",
      "Epoch: 007/050 | Batch 0150/0196 | Cost: 1.6429\n",
      "Epoch: 007/050 | Train: 39.406%\n",
      "Time elapsed: 2.35 min\n",
      "Epoch: 008/050 | Batch 0000/0196 | Cost: 1.5671\n",
      "Epoch: 008/050 | Batch 0150/0196 | Cost: 1.5692\n",
      "Epoch: 008/050 | Train: 41.852%\n",
      "Time elapsed: 2.68 min\n",
      "Epoch: 009/050 | Batch 0000/0196 | Cost: 1.6423\n",
      "Epoch: 009/050 | Batch 0150/0196 | Cost: 1.5157\n",
      "Epoch: 009/050 | Train: 42.832%\n",
      "Time elapsed: 3.02 min\n",
      "Epoch: 010/050 | Batch 0000/0196 | Cost: 1.5104\n",
      "Epoch: 010/050 | Batch 0150/0196 | Cost: 1.4086\n",
      "Epoch: 010/050 | Train: 44.496%\n",
      "Time elapsed: 3.36 min\n",
      "Epoch: 011/050 | Batch 0000/0196 | Cost: 1.6345\n",
      "Epoch: 011/050 | Batch 0150/0196 | Cost: 1.4711\n",
      "Epoch: 011/050 | Train: 44.582%\n",
      "Time elapsed: 3.70 min\n",
      "Epoch: 012/050 | Batch 0000/0196 | Cost: 1.5480\n",
      "Epoch: 012/050 | Batch 0150/0196 | Cost: 1.5178\n",
      "Epoch: 012/050 | Train: 46.584%\n",
      "Time elapsed: 4.04 min\n",
      "Epoch: 013/050 | Batch 0000/0196 | Cost: 1.4267\n",
      "Epoch: 013/050 | Batch 0150/0196 | Cost: 1.4330\n",
      "Epoch: 013/050 | Train: 46.268%\n",
      "Time elapsed: 4.38 min\n",
      "Epoch: 014/050 | Batch 0000/0196 | Cost: 1.4276\n",
      "Epoch: 014/050 | Batch 0150/0196 | Cost: 1.3600\n",
      "Epoch: 014/050 | Train: 47.486%\n",
      "Time elapsed: 4.72 min\n",
      "Epoch: 015/050 | Batch 0000/0196 | Cost: 1.3050\n",
      "Epoch: 015/050 | Batch 0150/0196 | Cost: 1.3514\n",
      "Epoch: 015/050 | Train: 47.986%\n",
      "Time elapsed: 5.06 min\n",
      "Epoch: 016/050 | Batch 0000/0196 | Cost: 1.5120\n",
      "Epoch: 016/050 | Batch 0150/0196 | Cost: 1.3317\n",
      "Epoch: 016/050 | Train: 48.294%\n",
      "Time elapsed: 5.40 min\n",
      "Epoch: 017/050 | Batch 0000/0196 | Cost: 1.5232\n",
      "Epoch: 017/050 | Batch 0150/0196 | Cost: 1.3222\n",
      "Epoch: 017/050 | Train: 49.158%\n",
      "Time elapsed: 5.74 min\n",
      "Epoch: 018/050 | Batch 0000/0196 | Cost: 1.4450\n",
      "Epoch: 018/050 | Batch 0150/0196 | Cost: 1.3963\n",
      "Epoch: 018/050 | Train: 49.628%\n",
      "Time elapsed: 6.08 min\n",
      "Epoch: 019/050 | Batch 0000/0196 | Cost: 1.3930\n",
      "Epoch: 019/050 | Batch 0150/0196 | Cost: 1.4259\n",
      "Epoch: 019/050 | Train: 50.140%\n",
      "Time elapsed: 6.42 min\n",
      "Epoch: 020/050 | Batch 0000/0196 | Cost: 1.5090\n",
      "Epoch: 020/050 | Batch 0150/0196 | Cost: 1.2891\n",
      "Epoch: 020/050 | Train: 51.298%\n",
      "Time elapsed: 6.76 min\n",
      "Epoch: 021/050 | Batch 0000/0196 | Cost: 1.3845\n",
      "Epoch: 021/050 | Batch 0150/0196 | Cost: 1.3206\n",
      "Epoch: 021/050 | Train: 50.642%\n",
      "Time elapsed: 7.10 min\n",
      "Epoch: 022/050 | Batch 0000/0196 | Cost: 1.4059\n",
      "Epoch: 022/050 | Batch 0150/0196 | Cost: 1.4076\n",
      "Epoch: 022/050 | Train: 52.204%\n",
      "Time elapsed: 7.44 min\n",
      "Epoch: 023/050 | Batch 0000/0196 | Cost: 1.2708\n",
      "Epoch: 023/050 | Batch 0150/0196 | Cost: 1.2555\n",
      "Epoch: 023/050 | Train: 52.876%\n",
      "Time elapsed: 7.78 min\n",
      "Epoch: 024/050 | Batch 0000/0196 | Cost: 1.1975\n",
      "Epoch: 024/050 | Batch 0150/0196 | Cost: 1.2196\n",
      "Epoch: 024/050 | Train: 53.576%\n",
      "Time elapsed: 8.12 min\n",
      "Epoch: 025/050 | Batch 0000/0196 | Cost: 1.2942\n",
      "Epoch: 025/050 | Batch 0150/0196 | Cost: 1.2967\n",
      "Epoch: 025/050 | Train: 53.844%\n",
      "Time elapsed: 8.46 min\n",
      "Epoch: 026/050 | Batch 0000/0196 | Cost: 1.2837\n",
      "Epoch: 026/050 | Batch 0150/0196 | Cost: 1.3414\n",
      "Epoch: 026/050 | Train: 54.562%\n",
      "Time elapsed: 8.81 min\n",
      "Epoch: 027/050 | Batch 0000/0196 | Cost: 1.2773\n",
      "Epoch: 027/050 | Batch 0150/0196 | Cost: 1.2936\n",
      "Epoch: 027/050 | Train: 53.750%\n",
      "Time elapsed: 9.14 min\n",
      "Epoch: 028/050 | Batch 0000/0196 | Cost: 1.2488\n",
      "Epoch: 028/050 | Batch 0150/0196 | Cost: 1.2489\n",
      "Epoch: 028/050 | Train: 55.114%\n",
      "Time elapsed: 9.48 min\n",
      "Epoch: 029/050 | Batch 0000/0196 | Cost: 1.2550\n",
      "Epoch: 029/050 | Batch 0150/0196 | Cost: 1.2256\n",
      "Epoch: 029/050 | Train: 53.806%\n",
      "Time elapsed: 9.82 min\n",
      "Epoch: 030/050 | Batch 0000/0196 | Cost: 1.2776\n",
      "Epoch: 030/050 | Batch 0150/0196 | Cost: 1.3692\n",
      "Epoch: 030/050 | Train: 56.104%\n",
      "Time elapsed: 10.16 min\n",
      "Epoch: 031/050 | Batch 0000/0196 | Cost: 1.2542\n",
      "Epoch: 031/050 | Batch 0150/0196 | Cost: 1.2809\n",
      "Epoch: 031/050 | Train: 56.256%\n",
      "Time elapsed: 10.50 min\n",
      "Epoch: 032/050 | Batch 0000/0196 | Cost: 1.1649\n",
      "Epoch: 032/050 | Batch 0150/0196 | Cost: 1.2762\n",
      "Epoch: 032/050 | Train: 55.820%\n",
      "Time elapsed: 10.84 min\n",
      "Epoch: 033/050 | Batch 0000/0196 | Cost: 1.2666\n",
      "Epoch: 033/050 | Batch 0150/0196 | Cost: 1.2294\n",
      "Epoch: 033/050 | Train: 55.314%\n",
      "Time elapsed: 11.18 min\n",
      "Epoch: 034/050 | Batch 0000/0196 | Cost: 1.1542\n",
      "Epoch: 034/050 | Batch 0150/0196 | Cost: 1.2219\n",
      "Epoch: 034/050 | Train: 57.514%\n",
      "Time elapsed: 11.52 min\n",
      "Epoch: 035/050 | Batch 0000/0196 | Cost: 1.1006\n",
      "Epoch: 035/050 | Batch 0150/0196 | Cost: 1.2530\n",
      "Epoch: 035/050 | Train: 57.442%\n",
      "Time elapsed: 11.86 min\n",
      "Epoch: 036/050 | Batch 0000/0196 | Cost: 1.1612\n",
      "Epoch: 036/050 | Batch 0150/0196 | Cost: 1.1750\n",
      "Epoch: 036/050 | Train: 57.866%\n",
      "Time elapsed: 12.19 min\n",
      "Epoch: 037/050 | Batch 0000/0196 | Cost: 1.2728\n",
      "Epoch: 037/050 | Batch 0150/0196 | Cost: 1.2318\n",
      "Epoch: 037/050 | Train: 57.824%\n",
      "Time elapsed: 12.53 min\n",
      "Epoch: 038/050 | Batch 0000/0196 | Cost: 1.2060\n",
      "Epoch: 038/050 | Batch 0150/0196 | Cost: 1.2510\n",
      "Epoch: 038/050 | Train: 56.996%\n",
      "Time elapsed: 12.87 min\n",
      "Epoch: 039/050 | Batch 0000/0196 | Cost: 1.0534\n",
      "Epoch: 039/050 | Batch 0150/0196 | Cost: 1.2304\n",
      "Epoch: 039/050 | Train: 59.268%\n",
      "Time elapsed: 13.21 min\n",
      "Epoch: 040/050 | Batch 0000/0196 | Cost: 1.1333\n",
      "Epoch: 040/050 | Batch 0150/0196 | Cost: 1.0861\n",
      "Epoch: 040/050 | Train: 59.360%\n",
      "Time elapsed: 13.55 min\n",
      "Epoch: 041/050 | Batch 0000/0196 | Cost: 1.1318\n",
      "Epoch: 041/050 | Batch 0150/0196 | Cost: 1.1789\n",
      "Epoch: 041/050 | Train: 60.284%\n",
      "Time elapsed: 13.89 min\n",
      "Epoch: 042/050 | Batch 0000/0196 | Cost: 1.1104\n",
      "Epoch: 042/050 | Batch 0150/0196 | Cost: 1.2120\n",
      "Epoch: 042/050 | Train: 59.580%\n",
      "Time elapsed: 14.23 min\n",
      "Epoch: 043/050 | Batch 0000/0196 | Cost: 1.1216\n",
      "Epoch: 043/050 | Batch 0150/0196 | Cost: 1.1255\n",
      "Epoch: 043/050 | Train: 59.894%\n",
      "Time elapsed: 14.57 min\n",
      "Epoch: 044/050 | Batch 0000/0196 | Cost: 1.1344\n",
      "Epoch: 044/050 | Batch 0150/0196 | Cost: 1.2295\n",
      "Epoch: 044/050 | Train: 60.898%\n",
      "Time elapsed: 14.91 min\n",
      "Epoch: 045/050 | Batch 0000/0196 | Cost: 1.1358\n",
      "Epoch: 045/050 | Batch 0150/0196 | Cost: 1.0987\n",
      "Epoch: 045/050 | Train: 61.258%\n",
      "Time elapsed: 15.25 min\n",
      "Epoch: 046/050 | Batch 0000/0196 | Cost: 1.1416\n",
      "Epoch: 046/050 | Batch 0150/0196 | Cost: 1.1000\n",
      "Epoch: 046/050 | Train: 60.392%\n",
      "Time elapsed: 15.58 min\n",
      "Epoch: 047/050 | Batch 0000/0196 | Cost: 1.2154\n",
      "Epoch: 047/050 | Batch 0150/0196 | Cost: 1.1993\n",
      "Epoch: 047/050 | Train: 59.848%\n",
      "Time elapsed: 15.93 min\n",
      "Epoch: 048/050 | Batch 0000/0196 | Cost: 1.1209\n",
      "Epoch: 048/050 | Batch 0150/0196 | Cost: 1.1330\n",
      "Epoch: 048/050 | Train: 62.328%\n",
      "Time elapsed: 16.26 min\n",
      "Epoch: 049/050 | Batch 0000/0196 | Cost: 1.0537\n",
      "Epoch: 049/050 | Batch 0150/0196 | Cost: 1.0301\n",
      "Epoch: 049/050 | Train: 61.910%\n",
      "Time elapsed: 16.60 min\n",
      "Epoch: 050/050 | Batch 0000/0196 | Cost: 1.0365\n",
      "Epoch: 050/050 | Batch 0150/0196 | Cost: 1.1937\n",
      "Epoch: 050/050 | Train: 62.252%\n",
      "Time elapsed: 16.94 min\n",
      "Total Training Time: 16.94 min\n",
      "Test accuracy: 60.96%\n",
      "Total Time: 16.96 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 150:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n",
    "\n",
    "\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))\n",
    "    \n",
    "print('Total Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy       1.15.4\n",
      "pandas      0.23.4\n",
      "torch       1.0.1.post2\n",
      "PIL.Image   5.3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
