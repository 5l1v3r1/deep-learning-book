{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Model-Zoo----Convolutional-Neural-Network-(VGG16)\" data-toc-modified-id=\"Model-Zoo----Convolutional-Neural-Network-(VGG16)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Model Zoo -- Convolutional Neural Network (VGG16)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Settings-and-Dataset\" data-toc-modified-id=\"Settings-and-Dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Settings and Dataset</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Evaluation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEBilEjLj5wY"
   },
   "source": [
    "*Accompanying code examples of the book \"Introduction to Artificial Neural Networks and Deep Learning: A Practical Guide with Applications in Python\" by [Sebastian Raschka](https://sebastianraschka.com). All code examples are released under the [MIT license](https://github.com/rasbt/deep-learning-book/blob/master/LICENSE). If you find this content useful, please consider supporting the work by buying a [copy of the book](https://leanpub.com/ann-and-deeplearning).*\n",
    "  \n",
    "Other code examples and content are available on [GitHub](https://github.com/rasbt/deep-learning-book). The PDF and ebook versions of the book are available through [Leanpub](https://leanpub.com/ann-and-deeplearning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1524974472601,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "GOzuY8Yvj5wb",
    "outputId": "c19362ce-f87a-4cc2-84cc-8d7b4b9e6007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.6.8\n",
      "IPython 7.2.0\n",
      "\n",
      "torch 1.0.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEu9MiOxj5wk"
   },
   "source": [
    "- Runs on CPU (not recommended here) or GPU (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rH4XmErYj5wm"
   },
   "source": [
    "# Model Zoo -- Convolutional Neural Network (VGG16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkoGLH_Tj5wn"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ORj09gnrj5wp"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvgJ_0i7j5wt"
   },
   "source": [
    "## Settings and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23936,
     "status": "ok",
     "timestamp": 1524974497505,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "NnT0sZIwj5wu",
    "outputId": "55aed925-d17e-4c6a-8c71-0d9b3bde5637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:3\n",
      "Files already downloaded and verified\n",
      "Image batch dimensions: torch.Size([128, 3, 32, 32])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "# Hyperparameters\n",
    "random_seed = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Architecture\n",
    "num_features = 784\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "##########################\n",
    "### MNIST DATASET\n",
    "##########################\n",
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "train_dataset = datasets.CIFAR10(root='data', \n",
    "                                 train=True, \n",
    "                                 transform=transforms.ToTensor(),\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='data', \n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6hghKPxj5w0"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_lza9t_uj5w1"
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "class VGG16(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(VGG16, self).__init__()\n",
    "        \n",
    "        # calculate same padding:\n",
    "        # (w - k + 2*p)/s + 1 = o\n",
    "        # => p = (s(o-1) - w + k)/2\n",
    "        \n",
    "        self.block_1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          # (1(32-1)- 32 + 3)/2 = 1\n",
    "                          padding=1), \n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=128,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_3 = nn.Sequential(        \n",
    "                nn.Conv2d(in_channels=128,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),        \n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "          \n",
    "        self.block_4 = nn.Sequential(   \n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),        \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),        \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block_5 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),            \n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),    \n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))             \n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "                nn.Linear(512, 4096),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.Linear(4096, num_classes)\n",
    "        )\n",
    "            \n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                #n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                #m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "                m.weight.detach().normal_(0, 0.05)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.detach().zero_()\n",
    "            elif isinstance(m, torch.nn.Linear):\n",
    "                m.weight.detach().normal_(0, 0.05)\n",
    "                m.bias.detach().detach().zero_()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.block_5(x)\n",
    "        logits = self.classifier(x.view(-1, 512))\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "\n",
    "        return logits, probas\n",
    "\n",
    "    \n",
    "torch.manual_seed(random_seed)\n",
    "model = VGG16(num_features=num_features,\n",
    "              num_classes=num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAodboScj5w6"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2384585,
     "status": "ok",
     "timestamp": 1524976888520,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "Dzh3ROmRj5w7",
    "outputId": "5f8fd8c9-b076-403a-b0b7-fd2d498b48d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/0391 | Cost: 302.2942\n",
      "Epoch: 001/010 | Batch 0050/0391 | Cost: 2.3886\n",
      "Epoch: 001/010 | Batch 0100/0391 | Cost: 2.1237\n",
      "Epoch: 001/010 | Batch 0150/0391 | Cost: 1.9836\n",
      "Epoch: 001/010 | Batch 0200/0391 | Cost: 2.0445\n",
      "Epoch: 001/010 | Batch 0250/0391 | Cost: 1.8649\n",
      "Epoch: 001/010 | Batch 0300/0391 | Cost: 1.9532\n",
      "Epoch: 001/010 | Batch 0350/0391 | Cost: 1.5750\n",
      "Epoch: 001/010 | Train: 35.928% | Valid: 35.312%\n",
      "Time elapsed: 0.55 min\n",
      "Epoch: 002/010 | Batch 0000/0391 | Cost: 1.7429\n",
      "Epoch: 002/010 | Batch 0050/0391 | Cost: 1.7827\n",
      "Epoch: 002/010 | Batch 0100/0391 | Cost: 1.5168\n",
      "Epoch: 002/010 | Batch 0150/0391 | Cost: 1.5408\n",
      "Epoch: 002/010 | Batch 0200/0391 | Cost: 1.5745\n",
      "Epoch: 002/010 | Batch 0250/0391 | Cost: 1.4727\n",
      "Epoch: 002/010 | Batch 0300/0391 | Cost: 1.4974\n",
      "Epoch: 002/010 | Batch 0350/0391 | Cost: 1.3535\n",
      "Epoch: 002/010 | Train: 44.474% | Valid: 43.359%\n",
      "Time elapsed: 1.10 min\n",
      "Epoch: 003/010 | Batch 0000/0391 | Cost: 1.5447\n",
      "Epoch: 003/010 | Batch 0050/0391 | Cost: 1.2935\n",
      "Epoch: 003/010 | Batch 0100/0391 | Cost: 1.3931\n",
      "Epoch: 003/010 | Batch 0150/0391 | Cost: 1.2969\n",
      "Epoch: 003/010 | Batch 0200/0391 | Cost: 1.2404\n",
      "Epoch: 003/010 | Batch 0250/0391 | Cost: 1.1129\n",
      "Epoch: 003/010 | Batch 0300/0391 | Cost: 1.2035\n",
      "Epoch: 003/010 | Batch 0350/0391 | Cost: 1.2562\n",
      "Epoch: 003/010 | Train: 56.592% | Valid: 56.797%\n",
      "Time elapsed: 1.66 min\n",
      "Epoch: 004/010 | Batch 0000/0391 | Cost: 0.9996\n",
      "Epoch: 004/010 | Batch 0050/0391 | Cost: 1.1521\n",
      "Epoch: 004/010 | Batch 0100/0391 | Cost: 1.1830\n",
      "Epoch: 004/010 | Batch 0150/0391 | Cost: 1.0458\n",
      "Epoch: 004/010 | Batch 0200/0391 | Cost: 1.1362\n",
      "Epoch: 004/010 | Batch 0250/0391 | Cost: 1.2075\n",
      "Epoch: 004/010 | Batch 0300/0391 | Cost: 1.1249\n",
      "Epoch: 004/010 | Batch 0350/0391 | Cost: 1.1922\n",
      "Epoch: 004/010 | Train: 65.720% | Valid: 65.469%\n",
      "Time elapsed: 2.21 min\n",
      "Epoch: 005/010 | Batch 0000/0391 | Cost: 0.9109\n",
      "Epoch: 005/010 | Batch 0050/0391 | Cost: 0.9355\n",
      "Epoch: 005/010 | Batch 0100/0391 | Cost: 1.2143\n",
      "Epoch: 005/010 | Batch 0150/0391 | Cost: 1.0014\n",
      "Epoch: 005/010 | Batch 0200/0391 | Cost: 1.0831\n",
      "Epoch: 005/010 | Batch 0250/0391 | Cost: 0.8249\n",
      "Epoch: 005/010 | Batch 0300/0391 | Cost: 0.9447\n",
      "Epoch: 005/010 | Batch 0350/0391 | Cost: 1.1146\n",
      "Epoch: 005/010 | Train: 69.574% | Valid: 68.047%\n",
      "Time elapsed: 2.78 min\n",
      "Epoch: 006/010 | Batch 0000/0391 | Cost: 0.9597\n",
      "Epoch: 006/010 | Batch 0050/0391 | Cost: 0.8052\n",
      "Epoch: 006/010 | Batch 0100/0391 | Cost: 0.9593\n",
      "Epoch: 006/010 | Batch 0150/0391 | Cost: 0.7663\n",
      "Epoch: 006/010 | Batch 0200/0391 | Cost: 0.7485\n",
      "Epoch: 006/010 | Batch 0250/0391 | Cost: 0.9885\n",
      "Epoch: 006/010 | Batch 0300/0391 | Cost: 1.1307\n",
      "Epoch: 006/010 | Batch 0350/0391 | Cost: 0.9209\n",
      "Epoch: 006/010 | Train: 69.378% | Valid: 71.875%\n",
      "Time elapsed: 3.35 min\n",
      "Epoch: 007/010 | Batch 0000/0391 | Cost: 0.9159\n",
      "Epoch: 007/010 | Batch 0050/0391 | Cost: 0.7905\n",
      "Epoch: 007/010 | Batch 0100/0391 | Cost: 0.9323\n",
      "Epoch: 007/010 | Batch 0150/0391 | Cost: 1.0764\n",
      "Epoch: 007/010 | Batch 0200/0391 | Cost: 0.7238\n",
      "Epoch: 007/010 | Batch 0250/0391 | Cost: 0.8099\n",
      "Epoch: 007/010 | Batch 0300/0391 | Cost: 0.8057\n",
      "Epoch: 007/010 | Batch 0350/0391 | Cost: 0.9478\n",
      "Epoch: 007/010 | Train: 72.772% | Valid: 72.969%\n",
      "Time elapsed: 3.92 min\n",
      "Epoch: 008/010 | Batch 0000/0391 | Cost: 0.8087\n",
      "Epoch: 008/010 | Batch 0050/0391 | Cost: 0.7926\n",
      "Epoch: 008/010 | Batch 0100/0391 | Cost: 0.5719\n",
      "Epoch: 008/010 | Batch 0150/0391 | Cost: 0.6742\n",
      "Epoch: 008/010 | Batch 0200/0391 | Cost: 0.9315\n",
      "Epoch: 008/010 | Batch 0250/0391 | Cost: 0.8293\n",
      "Epoch: 008/010 | Batch 0300/0391 | Cost: 1.0037\n",
      "Epoch: 008/010 | Batch 0350/0391 | Cost: 0.7883\n",
      "Epoch: 008/010 | Train: 75.954% | Valid: 74.375%\n",
      "Time elapsed: 4.49 min\n",
      "Epoch: 009/010 | Batch 0000/0391 | Cost: 0.8411\n",
      "Epoch: 009/010 | Batch 0050/0391 | Cost: 0.6063\n",
      "Epoch: 009/010 | Batch 0100/0391 | Cost: 0.7495\n",
      "Epoch: 009/010 | Batch 0150/0391 | Cost: 0.7081\n",
      "Epoch: 009/010 | Batch 0200/0391 | Cost: 0.6729\n",
      "Epoch: 009/010 | Batch 0250/0391 | Cost: 0.5845\n",
      "Epoch: 009/010 | Batch 0300/0391 | Cost: 0.7017\n",
      "Epoch: 009/010 | Batch 0350/0391 | Cost: 0.6521\n",
      "Epoch: 009/010 | Train: 79.880% | Valid: 80.781%\n",
      "Time elapsed: 5.06 min\n",
      "Epoch: 010/010 | Batch 0000/0391 | Cost: 0.5651\n",
      "Epoch: 010/010 | Batch 0050/0391 | Cost: 0.5848\n",
      "Epoch: 010/010 | Batch 0100/0391 | Cost: 0.5359\n",
      "Epoch: 010/010 | Batch 0150/0391 | Cost: 0.6922\n",
      "Epoch: 010/010 | Batch 0200/0391 | Cost: 0.6631\n",
      "Epoch: 010/010 | Batch 0250/0391 | Cost: 0.6641\n",
      "Epoch: 010/010 | Batch 0300/0391 | Cost: 0.6957\n",
      "Epoch: 010/010 | Batch 0350/0391 | Cost: 0.7105\n",
      "Epoch: 010/010 | Train: 80.212% | Valid: 82.266%\n",
      "Time elapsed: 5.63 min\n",
      "Total Training Time: 5.63 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader, train=False, validation=False):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "        \n",
    "        if not train:\n",
    "            if not validation and i < 10:\n",
    "                continue\n",
    "            elif validation and i >= 10:\n",
    "                continue\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, num_epochs, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%% | Valid: %.3f%%' % (\n",
    "              epoch+1, num_epochs, \n",
    "              compute_accuracy(model, train_loader, train=True),\n",
    "              compute_accuracy(model, train_loader, train=False, validation=True)))\n",
    "\n",
    "\n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paaeEQHQj5xC"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6514,
     "status": "ok",
     "timestamp": 1524976895054,
     "user": {
      "displayName": "Sebastian Raschka",
      "photoUrl": "//lh6.googleusercontent.com/-cxK6yOSQ6uE/AAAAAAAAAAI/AAAAAAAAIfw/P9ar_CHsKOQ/s50-c-k-no/photo.jpg",
      "userId": "118404394130788869227"
     },
     "user_tz": 240
    },
    "id": "gzQMWKq5j5xE",
    "outputId": "de7dc005-5eeb-4177-9f9f-d9b5d1358db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 70.68%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy       1.15.4\n",
      "torch       1.0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -iv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "convnet-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
